\section{Methodology}
\label{sec:method}
% include the figures path relative to the master file
\graphicspath{ {./content/method/figures/} }
As mentioned in the Sect.\,\ref{sec:descr}, the proposed framework do not rely on pre-processing an segmentation and focus only on feature detection, extraction and classification.

{\color{red} Add a graph with the classification scheme}

\subsection{Feature extraction}

\subsubsection{Low-level features}

In clinical environment, the prognosis of early stage melanoma relies upon visual cues as stated by the ``ABCDE'' rule.
As introduced in Sect.\,\ref{sec:descr}, this lexicon characterizes cancerous lesions based on their local textures, shapes, and colors from dermoscopic images.
Thus, in order to mimic clinicians assessment, the choice of low-level features encoding similar contextual information is beneficial{\color{red}-crucial?}.
In that regard, three low-level features in line with the previous requirements are used and presented into details in the remainder of this section.
Furthermore, these features are locally extracted by partitioning the dermoscopic images into patches.

% Low-level feature are used to encode the texture and color aspects of dermoscopic images. In this regard, \ac{sift}~\cite{lowe1999object} (named \emph{\ac{sift}}) and two color descriptors: the first color descriptor consists of Hue and opponent color space angle histogram~\cite{van2006coloring}(named \emph{C1}), and the second color descriptor is based on the concatenation of the R, G and B intensities (named \emph{C2}). All these features are extracted from local patches in the dermoscopic images.

\begin{description}
\item[Dense \acf{sift}] descriptors are used to encode the local gradient information using an histogram-based representation~\cite{lowe1999object}. 
\ac{sift} descriptors are extracted over a regular grid such that each grid point is fixed at the center of each image patch.
Typically, a region around the center is divided into $4 \times 4$ sub-regions from which a $8$-bins histogram of the gradient orientations weighted by the gradient magnitudes is computed.
Finally, these histograms are concatenated to build the final descriptor with a final size of $128$ dimensions.
The \ac{sift} implementation used in this work is provided by Vedaldi~\emph{et~al.}~\cite{vedaldi2010vlfeat}.

\item[The opponent color space angle and hue histogram (\emph{C1})] have been first proposed by Van de Weijer and Schmidt as local color features~\cite{van2006coloring}.
These descriptors are robust to photometric variations (i.e., shadow, shading, specularities, and light source changes) as well as geometrical variations (i.e, viewpoint, zoom, and object orientation).
The hue and angle of opponent color space are formulated as shown in Eq.\,\ref{eq:hue} and Eq.\,\ref{eq:theta}, respectively.
The opponent color space transformation is defined as in Eq.\,\ref{eq:opponent}.

\begin{align}
    \begin{pmatrix}
      \mathcal{O}_{1}\\\mathcal{O}_{2} \\\mathcal{O}_{3}
    \end{pmatrix} & =
                    \begin{pmatrix}
                      (R-G)/\sqrt{2}\\
                      (R+G-2B)/\sqrt{6}\\
                      (R+G+B)/\sqrt{3}
                    \end{pmatrix} \label{eq:opponent}\\
    H^{\mathcal{O}} & = \arctan\left(\frac{\sqrt{3}(R-G)}{R+G-2B}\right)\label{eq:hue}\\
    \theta_{d}^{\mathcal{O}} & = \arctan\left(\frac{\sqrt{3}(R'_{d}-G'_{d})}{R'_{d}+G'_{d}-2B'_{d}}\right)\label{eq:theta}
  \end{align}

\noindent where $d$ denotes the spatial coordinates of ($x$,$y$) and $R'_{d}$, $G'_{d}$, $B'_{d}$ denote the first order derivatives of $RGB$ with respect to the coordinates.

\item[The color intensities (\emph{C2})] represent the color information in a simplest form, their intensities.
This descriptor concatenates the color intensities R, G and B to create the feature descriptor.
\end{description}

\subsubsection{High-level features}
High-level descriptor is computed using sparse coding techniques. Sparse signal representation has become very popular in the past decades and lead to state-of-the-art results in various applications such as face recognition~\cite{wright2009robust}, image denoising, image inpainting~\cite{elad2006image}, and image classification~\cite{sidibe2015discrimination}. The main goal of sparse modeling is to efficiently represent the images as linear combination of a few typical patterns, called atoms, selected from the dictionary. Here, we intend to use sparse representation of the low-level extracted features for melanoma classification. Sparse coding consists of three main steps: (i) dictionary learning, (ii) low-level features projection, and (iii) feature pooling~\cite{rubinstein2008efficient}. 

The dictionary is learned using $K$-SVD which is a generalized version of $K$-means clustering and uses \ac{svd}. The dictionary is built such that:
\begin{equation}
  \argmin_{\mathbf{x}} \|\mathbf{y} - \mathbf{D}\mathbf{x}\|_{2} \qquad  \text{s.t.} \  \|\mathbf{x}\|_{1} \leq \lambda \,
\end{equation}

\noindent where $\mathbf{y}$ is a low-level descriptor, $\mathbf{x}$ is the sparse coded descriptor (i.e., high-level descriptor) with a sparsity level $\lambda$, and $\mathbf{D}$ is the dictionary with $K$ atoms.

Once the dictionary is learned, each low-level extracted feature from a patch can be projected using $\mathbf{D}$ to form a set of sparse codes. This set is further max-pooled to built a final global descriptor to characterize the whole image.
\subsection{Feature classification}

\subsubsection{Over-sampling from imbalanced dataset}

\subsubsection{\acf*{rf}}

The descriptor obtained after max-pooling is used to train and test a \ac{rf} classifier. 

\section{Contribution}
We propose a classification framework which do not rely on pre-processing and lesion segmentation and is based on sparse coded features. It is also presented that low-level features such as intensity values can be used directly for classification of the lesions within such framework. 




%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../master"
%%% End: 
