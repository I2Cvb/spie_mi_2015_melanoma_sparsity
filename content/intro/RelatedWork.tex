\section{Related Work}
\label{sec:rw}
In the past decade, numerous approaches have been proposed for automated recognition of melanoma lesions.
The developed methods are commonly based on clinical or dermoscopy modality.
As previously mentioned, these methods follow the usual classification framework of computer vision and consists of four common steps.
%and Rastgoo~\emph{et~al.}\cite{rastgoo2015automatic}
Korotkov~\emph{et~al.}\cite{korotkov2012computerized} summarize these methods and their properties.
Unfortunately, a fair comparison among the state-of-the-art presented methods is not possible due to lack of a benchmark and common datasets~\cite{rastgoo2015automatic,korotkov2012computerized}.
Nevertheless recently a public dataset ( PH$^{2}$ ) has been resealed for research purposes, thanks to Mendoncca~\emph{et~al.}\cite{mendoncca2013ph}.
Section~\ref{sec:exp} presents a detailed description of this dataset.

Subsequently, we emphasize on the most recent methods which are evaluated using this dataset.
Table~\ref{tab:rw} summarizes these methods. 
Barata~\emph{et~al.}\cite{barata2013two,barata2013role} and Ruela~\emph{et~al.}\cite{ruela2013role,ruela2013color} used different subsets of PH$^{2}$ dataset in their works~\cite{mendoncca2013ph}.
Ruela~\emph{et~al.}\cite{ruela2013role,ruela2013color} compared the role of shape and colors to detect melanoma~vs.~benign and dysplastic lesions using \ac{adb} classifier.
Concerning the same problem, Barata~\emph{et~al.}\cite{barata2013two} proposed to use \ac{bow} representation of colors and gradient features and compared different classifiers, such as \ac{adb}, kernel \ac{svm}, and k-\ac{nn}.
The configuration based on \ac{bow} representation and k-\ac{nn} classifier lead to the best results with \ac{se} and \ac{sp} of 100\% and 75\%, respectively.
%Their proposed algorithm achieved the highest \ac{se} and \ac{sp} of 100\% and 75\%, respectively, when \ac{bow} representation with k-\ac{nn} classifier was used.
The authors later used a similar scheme (\ac{bow} representation, k-\ac{nn} classifier, and histogram of opponent color space histogram) to compare the effects of manual and automatic segmentation in the classification process.
The results indicate that manual segmentation outperformed the automatic segmentation (\ac{se} and \ac{sp} of 98\% and 86\%, respectively).
%The similar classification scheme, \ac{bow} representation, k-\ac{nn} classifier, and histogram of opponent color space histogram, later was used by the same authors for comparing the effects of segmentation~\cite{barata2013towards}.
%In this study the authors compared the performance of their proposed system while automatic segmentation or manual segmentation provided by a specialist were used.
%The obtained results indicated that manual segmentation provided better performance than automatic segmentation (\ac{se} and \ac{sp} of 98\% and 86\%, respectively).
Feature space, \ac{ros} was used in all the aforementioned methods to tackle the imbalance problem.
%Random over sampling, in feature space, was used by all the aforementioned methods, in order to deal with imbalance problem. 

Abuzaghleh~\emph{et~al.}\cite{abuzaghleh2014automated} also used PH$^{2}$ dataset in which they proposed an automated recognition system based on color and shape features such as 2-D \ac{fft2}, \ac{dct2}, size and complexity features.
The authors proposed two classification approaches: (i) multi-class and (ii) two-level classification, both using \ac{svm} classifier.
%In both approaches \ac{svm} classifier was used.
In the latter approach, the first level classifies normal and abnormal lesions while the second level works only with the abnormally classified lesions to differentiate melanoma and dysplastic nevi.

In our previous work, we compared the effects of various colors, shape and texture features using ensemble approaches~\cite{rastgoo2015ensemble}.
The features were extracted from the segmented area and \ac{dos} was used instead of \ac{ros}~\cite{rastgoo2015ensemble}.
The best results with \ac{se} and \ac{sp} of 94\% and 92\%, respectively, was achieved using \ac{rf} ensemble and combination of color and texture features.
%Using \ac{rf} ensemble and combination of color and texture features the \ac{se} and \ac{sp} of 94\% and 92\%, was achieved, respectively.


%\begin{table}
\begin{table}
	\caption{Summary of the proposed classification methods using PH$^{2}$ dataset.}
\resizebox{1\textwidth}{!}{
\scriptsize{
\begin{threeparttable}
\begin{tabular}{l c c cc	c   c cc}
\toprule
Ref & Segmentation & features & \multicolumn{2}{c}{Classification} & Balancing & Validation & \multicolumn{2}{c}{Best performance} \\
\cmidrule{4-5}\cmidrule{8-9}
    & 			   & 		  & Classifier & Representation  &           &  & \ac{se} & \ac{sp}\\
\midrule 
\multirow{2}{*}{Ruela~\emph{et~al.}}\cite{ruela2013role} & \multirow{2}{*}{$\checkmark$} & Shape, \acs{fd}\tnote{1} & \acs{adb} & - & \ac{ros} & OvA\tnote{1}  & 92 & 74 \\ \\
\multirow{2}{*}{Ruela~\emph{et~al.}}\cite{ruela2013color} & \multirow{2}{*}{$\checkmark$} & Color statistics & k-\acs{nn}, \acs{adb} & - & \ac{ros} & OvA  & 96 & 83 \\ \\
\multirow{2}{*}{Barata~\emph{et~al.}\cite{barata2013two}} &  \multirow{2}{*}{$\checkmark$} & Opponent histogram & \acs{adb}, \acs{svm} & \acs{bow} & \multirow{2}{*}{\acs{ros}} & 10-fold\tnote{2} & \multirow{2}{*}{100} & \multirow{2}{*}{75}   \\
& & gradients & k-\ac{nn} & - &  & OvA &  &\\ \\

Barata~\emph{et~al.}\cite{barata2013towards} & $\checkmark$ & Opponent histogram & k-\acs{nn} & \acs{bow} & \acs{ros} & 10-fold & 98 & 86  \\ \\


Abuzaghleh~\emph{et~al.}\cite{abuzaghleh2014automated} & $\checkmark$ & \acs{fft2}, \acs{dct2} & \ac{svm} & - & - & - & 97.7 & - \\ \\

\multirow{3}{*}{Rastgoo~\emph{et~al.}\cite{rastgoo2015ensemble}} & \multirow{3}{*}{$\checkmark$} & Shape, color statistics & \multirow{3}{*}{-} & \multirow{2}{*}{\acs{rf}}  & \multirow{3}{*}{\acs{dos}}& \multirow{3}{*}{OvA} & \multirow{3}{*}{94} & \multirow{3}{*}{92}\\
&  & opponent angle and Hue histogram & &   &  &  & & \\
&  & CLBP, GLCM, HoG, Gabor\tnote{3} & & LC\tnote{3} & & & & \\
\bottomrule
\end{tabular}
 \begin{tablenotes}
  \item[1] \acf{fd}, One versus all (OvA).
  \item[1] k-fold corss validation.
  \item[2] Completed Local Binary Pattern (CLBP), Gray-Level Co-occurrence Matrix (GLCM), Histogram of Gradients (HoG), Learner combination (LC).
  
%  \item[2] 24 neighbourhood, rotation invariant, uniform and normalized histogram
%  \item[3] \textit{D} stands for distance in pixel and \textit{G} quantized number of grey levels
  \end{tablenotes}

\end{threeparttable}
}}
\label{tab:rw}
\end{table}


%Barata 1 
%One vs all 
%random over sampling 
%local 10 -fold 
%global one vs all 
%
%
%Barata 3 Bag of Words 
%(25 melanomas and 151 nevi).
%10 fold - classification
%random over sampling 
%
%Barata 2 
%10 fold classification
%random over sampling 
%
%Ruela 1 and 2 
%One vs all 
%random over sampling 
%
%Abuzaghleh 
%75 train, 
%25 test 
%Mel, Dys, Nor
%97.7, 91.3, 90.6 
%No info about balancing 
%
%Rastgoo et al 

